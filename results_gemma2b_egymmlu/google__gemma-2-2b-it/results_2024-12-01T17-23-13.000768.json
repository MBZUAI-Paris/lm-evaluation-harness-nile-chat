{
  "results": {
    "egyptianmmlu": {
      "acc,none": 0.22954545454545455,
      "acc_stderr,none": 0.01991430216378017,
      "alias": "EgyptianMMLU"
    },
    "egyptianmmlu_ar_mmlu": {
      "acc,none": 0.2619047619047619,
      "acc_stderr,none": 0.029991180361414575,
      "alias": " - ArabicMMLU"
    },
    "egyptianmmlu_accounting": {
      "alias": "  - accounting",
      "acc,none": 0.2,
      "acc_stderr,none": 0.13333333333333333
    },
    "egyptianmmlu_arabic_language": {
      "alias": "  - arabic language",
      "acc,none": 0.1,
      "acc_stderr,none": 0.09999999999999999
    },
    "egyptianmmlu_arabic_language_(general)": {
      "alias": "  - arabic language (general)",
      "acc,none": 0.1,
      "acc_stderr,none": 0.09999999999999999
    },
    "egyptianmmlu_arabic_language_(grammar)": {
      "alias": "  - arabic language (grammar)",
      "acc,none": 0.3,
      "acc_stderr,none": 0.15275252316519464
    },
    "egyptianmmlu_biology": {
      "alias": "  - biology",
      "acc,none": 0.4,
      "acc_stderr,none": 0.1632993161855452
    },
    "egyptianmmlu_civics": {
      "alias": "  - civics",
      "acc,none": 0.4,
      "acc_stderr,none": 0.16329931618554522
    },
    "egyptianmmlu_computer_science": {
      "alias": "  - computer science",
      "acc,none": 0.6,
      "acc_stderr,none": 0.16329931618554522
    },
    "egyptianmmlu_driving_test": {
      "alias": "  - driving test",
      "acc,none": 0.2,
      "acc_stderr,none": 0.13333333333333333
    },
    "egyptianmmlu_economics": {
      "alias": "  - economics",
      "acc,none": 0.1,
      "acc_stderr,none": 0.09999999999999999
    },
    "egyptianmmlu_general_knowledge": {
      "alias": "  - general knowledge",
      "acc,none": 0.4,
      "acc_stderr,none": 0.16329931618554522
    },
    "egyptianmmlu_geography": {
      "alias": "  - geography",
      "acc,none": 0.2,
      "acc_stderr,none": 0.13333333333333333
    },
    "egyptianmmlu_history": {
      "alias": "  - history",
      "acc,none": 0.5,
      "acc_stderr,none": 0.16666666666666666
    },
    "egyptianmmlu_islamic_studies": {
      "alias": "  - islamic studies",
      "acc,none": 0.3,
      "acc_stderr,none": 0.15275252316519466
    },
    "egyptianmmlu_law": {
      "alias": "  - law",
      "acc,none": 0.1,
      "acc_stderr,none": 0.09999999999999999
    },
    "egyptianmmlu_management_ar": {
      "alias": "  - management ar",
      "acc,none": 0.2,
      "acc_stderr,none": 0.13333333333333333
    },
    "egyptianmmlu_math": {
      "alias": "  - math",
      "acc,none": 0.4,
      "acc_stderr,none": 0.16329931618554522
    },
    "egyptianmmlu_natural_science": {
      "alias": "  - natural science",
      "acc,none": 0.0,
      "acc_stderr,none": 0.0
    },
    "egyptianmmlu_philosophy_ar": {
      "alias": "  - philosophy ar",
      "acc,none": 0.3,
      "acc_stderr,none": 0.15275252316519466
    },
    "egyptianmmlu_physics": {
      "alias": "  - physics",
      "acc,none": 0.4,
      "acc_stderr,none": 0.1632993161855452
    },
    "egyptianmmlu_political_science": {
      "alias": "  - political science",
      "acc,none": 0.1,
      "acc_stderr,none": 0.09999999999999999
    },
    "egyptianmmlu_social_science": {
      "alias": "  - social science",
      "acc,none": 0.2,
      "acc_stderr,none": 0.13333333333333333
    },
    "egyptianmmlu_mmlu": {
      "acc,none": 0.2,
      "acc_stderr,none": 0.026486473742749365,
      "alias": " - MMLU"
    },
    "egyptianmmlu_global_facts": {
      "alias": "  - global facts",
      "acc,none": 0.3,
      "acc_stderr,none": 0.15275252316519466
    },
    "egyptianmmlu_high_school_european_history": {
      "alias": "  - high school european history",
      "acc,none": 0.1,
      "acc_stderr,none": 0.09999999999999999
    },
    "egyptianmmlu_high_school_geography": {
      "alias": "  - high school geography",
      "acc,none": 0.3,
      "acc_stderr,none": 0.15275252316519464
    },
    "egyptianmmlu_high_school_government_and_politics": {
      "alias": "  - high school government and politics",
      "acc,none": 0.2,
      "acc_stderr,none": 0.13333333333333333
    },
    "egyptianmmlu_high_school_psychology": {
      "alias": "  - high school psychology",
      "acc,none": 0.1,
      "acc_stderr,none": 0.09999999999999999
    },
    "egyptianmmlu_high_school_statistics": {
      "alias": "  - high school statistics",
      "acc,none": 0.1,
      "acc_stderr,none": 0.09999999999999999
    },
    "egyptianmmlu_high_school_world_history": {
      "alias": "  - high school world history",
      "acc,none": 0.3,
      "acc_stderr,none": 0.15275252316519466
    },
    "egyptianmmlu_human_aging": {
      "alias": "  - human aging",
      "acc,none": 0.3,
      "acc_stderr,none": 0.15275252316519464
    },
    "egyptianmmlu_international_law": {
      "alias": "  - international law",
      "acc,none": 0.3,
      "acc_stderr,none": 0.15275252316519464
    },
    "egyptianmmlu_jurisprudence": {
      "alias": "  - jurisprudence",
      "acc,none": 0.1,
      "acc_stderr,none": 0.09999999999999999
    },
    "egyptianmmlu_logical_fallacies": {
      "alias": "  - logical fallacies",
      "acc,none": 0.3,
      "acc_stderr,none": 0.15275252316519464
    },
    "egyptianmmlu_management": {
      "alias": "  - management",
      "acc,none": 0.0,
      "acc_stderr,none": 0.0
    },
    "egyptianmmlu_marketing": {
      "alias": "  - marketing",
      "acc,none": 0.4,
      "acc_stderr,none": 0.1632993161855452
    },
    "egyptianmmlu_moral_disputes": {
      "alias": "  - moral disputes",
      "acc,none": 0.3,
      "acc_stderr,none": 0.15275252316519464
    },
    "egyptianmmlu_moral_scenarios": {
      "alias": "  - moral scenarios",
      "acc,none": 0.2,
      "acc_stderr,none": 0.13333333333333333
    },
    "egyptianmmlu_nutrition": {
      "alias": "  - nutrition",
      "acc,none": 0.0,
      "acc_stderr,none": 0.0
    },
    "egyptianmmlu_philosophy": {
      "alias": "  - philosophy",
      "acc,none": 0.4,
      "acc_stderr,none": 0.1632993161855452
    },
    "egyptianmmlu_professional_law": {
      "alias": "  - professional law",
      "acc,none": 0.1,
      "acc_stderr,none": 0.09999999999999999
    },
    "egyptianmmlu_professional_psychology": {
      "alias": "  - professional psychology",
      "acc,none": 0.3,
      "acc_stderr,none": 0.15275252316519464
    },
    "egyptianmmlu_public_relations": {
      "alias": "  - public relations",
      "acc,none": 0.0,
      "acc_stderr,none": 0.0
    },
    "egyptianmmlu_security_studies": {
      "alias": "  - security studies",
      "acc,none": 0.2,
      "acc_stderr,none": 0.13333333333333333
    },
    "egyptianmmlu_sociology": {
      "alias": "  - sociology",
      "acc,none": 0.1,
      "acc_stderr,none": 0.09999999999999999
    },
    "egyptianmmlu_world_religions": {
      "alias": "  - world religions",
      "acc,none": 0.2,
      "acc_stderr,none": 0.13333333333333333
    }
  },
  "groups": {
    "egyptianmmlu": {
      "acc,none": 0.22954545454545455,
      "acc_stderr,none": 0.01991430216378017,
      "alias": "EgyptianMMLU"
    },
    "egyptianmmlu_ar_mmlu": {
      "acc,none": 0.2619047619047619,
      "acc_stderr,none": 0.029991180361414575,
      "alias": " - ArabicMMLU"
    },
    "egyptianmmlu_mmlu": {
      "acc,none": 0.2,
      "acc_stderr,none": 0.026486473742749365,
      "alias": " - MMLU"
    }
  },
  "group_subtasks": {
    "egyptianmmlu_ar_mmlu": [
      "egyptianmmlu_history",
      "egyptianmmlu_philosophy_ar",
      "egyptianmmlu_civics",
      "egyptianmmlu_general_knowledge",
      "egyptianmmlu_natural_science",
      "egyptianmmlu_law",
      "egyptianmmlu_geography",
      "egyptianmmlu_arabic_language_(grammar)",
      "egyptianmmlu_islamic_studies",
      "egyptianmmlu_economics",
      "egyptianmmlu_accounting",
      "egyptianmmlu_computer_science",
      "egyptianmmlu_political_science",
      "egyptianmmlu_arabic_language_(general)",
      "egyptianmmlu_physics",
      "egyptianmmlu_biology",
      "egyptianmmlu_math",
      "egyptianmmlu_management_ar",
      "egyptianmmlu_arabic_language",
      "egyptianmmlu_driving_test",
      "egyptianmmlu_social_science"
    ],
    "egyptianmmlu_mmlu": [
      "egyptianmmlu_philosophy",
      "egyptianmmlu_global_facts",
      "egyptianmmlu_sociology",
      "egyptianmmlu_security_studies",
      "egyptianmmlu_nutrition",
      "egyptianmmlu_marketing",
      "egyptianmmlu_high_school_european_history",
      "egyptianmmlu_public_relations",
      "egyptianmmlu_international_law",
      "egyptianmmlu_high_school_government_and_politics",
      "egyptianmmlu_human_aging",
      "egyptianmmlu_management",
      "egyptianmmlu_moral_scenarios",
      "egyptianmmlu_high_school_geography",
      "egyptianmmlu_professional_psychology",
      "egyptianmmlu_professional_law",
      "egyptianmmlu_logical_fallacies",
      "egyptianmmlu_high_school_statistics",
      "egyptianmmlu_world_religions",
      "egyptianmmlu_high_school_psychology",
      "egyptianmmlu_jurisprudence",
      "egyptianmmlu_moral_disputes",
      "egyptianmmlu_high_school_world_history"
    ],
    "egyptianmmlu": [
      "egyptianmmlu_mmlu",
      "egyptianmmlu_ar_mmlu"
    ]
  },
  "configs": {
    "egyptianmmlu_accounting": {
      "task": "egyptianmmlu_accounting",
      "task_alias": "accounting",
      "tag": [
        "egyptianmmlu_social_sciences_tasks",
        "egyptianmmlu_ar_mmlu_tasks"
      ],
      "dataset_path": "MBZUAI-Paris/EgyptianMMLU",
      "dataset_name": "accounting",
      "dataset_kwargs": {
        "trust_remote_code": true
      },
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "def doc_to_text(doc):\n\n    subject = doc[\"subject_egyptian\"]\n    question = (\n        doc[\"question\"]\n        if doc[\"context\"] == \"\"\n        else f\"{doc['context']}\\n\\n{doc['question']}\"\n    )\n\n    options = []\n    for i, opt in enumerate(eval(doc[\"choices\"])):\n        options.append(f\"{alpha[i]} {opt}\")\n    doc_text = PROMPT.format(subject, question, \"\\n\".join(options))\n    return doc_text\n",
      "doc_to_target": "answer",
      "doc_to_choice": "def doc_to_choice(doc):\n    return [alpha[i][0] for i in range(len(eval(doc['choices'])))]\n",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0.0
      }
    },
    "egyptianmmlu_arabic_language": {
      "task": "egyptianmmlu_arabic_language",
      "task_alias": "arabic language",
      "tag": [
        "egyptianmmlu_language_tasks",
        "egyptianmmlu_ar_mmlu_tasks"
      ],
      "dataset_path": "MBZUAI-Paris/EgyptianMMLU",
      "dataset_name": "arabic_language",
      "dataset_kwargs": {
        "trust_remote_code": true
      },
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "def doc_to_text(doc):\n\n    subject = doc[\"subject_egyptian\"]\n    question = (\n        doc[\"question\"]\n        if doc[\"context\"] == \"\"\n        else f\"{doc['context']}\\n\\n{doc['question']}\"\n    )\n\n    options = []\n    for i, opt in enumerate(eval(doc[\"choices\"])):\n        options.append(f\"{alpha[i]} {opt}\")\n    doc_text = PROMPT.format(subject, question, \"\\n\".join(options))\n    return doc_text\n",
      "doc_to_target": "answer",
      "doc_to_choice": "def doc_to_choice(doc):\n    return [alpha[i][0] for i in range(len(eval(doc['choices'])))]\n",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0.0
      }
    },
    "egyptianmmlu_arabic_language_(general)": {
      "task": "egyptianmmlu_arabic_language_(general)",
      "task_alias": "arabic language (general)",
      "tag": [
        "egyptianmmlu_language_tasks",
        "egyptianmmlu_ar_mmlu_tasks"
      ],
      "dataset_path": "MBZUAI-Paris/EgyptianMMLU",
      "dataset_name": "arabic_language_(general)",
      "dataset_kwargs": {
        "trust_remote_code": true
      },
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "def doc_to_text(doc):\n\n    subject = doc[\"subject_egyptian\"]\n    question = (\n        doc[\"question\"]\n        if doc[\"context\"] == \"\"\n        else f\"{doc['context']}\\n\\n{doc['question']}\"\n    )\n\n    options = []\n    for i, opt in enumerate(eval(doc[\"choices\"])):\n        options.append(f\"{alpha[i]} {opt}\")\n    doc_text = PROMPT.format(subject, question, \"\\n\".join(options))\n    return doc_text\n",
      "doc_to_target": "answer",
      "doc_to_choice": "def doc_to_choice(doc):\n    return [alpha[i][0] for i in range(len(eval(doc['choices'])))]\n",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0.0
      }
    },
    "egyptianmmlu_arabic_language_(grammar)": {
      "task": "egyptianmmlu_arabic_language_(grammar)",
      "task_alias": "arabic language (grammar)",
      "tag": [
        "egyptianmmlu_language_tasks",
        "egyptianmmlu_ar_mmlu_tasks"
      ],
      "dataset_path": "MBZUAI-Paris/EgyptianMMLU",
      "dataset_name": "arabic_language_(grammar)",
      "dataset_kwargs": {
        "trust_remote_code": true
      },
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "def doc_to_text(doc):\n\n    subject = doc[\"subject_egyptian\"]\n    question = (\n        doc[\"question\"]\n        if doc[\"context\"] == \"\"\n        else f\"{doc['context']}\\n\\n{doc['question']}\"\n    )\n\n    options = []\n    for i, opt in enumerate(eval(doc[\"choices\"])):\n        options.append(f\"{alpha[i]} {opt}\")\n    doc_text = PROMPT.format(subject, question, \"\\n\".join(options))\n    return doc_text\n",
      "doc_to_target": "answer",
      "doc_to_choice": "def doc_to_choice(doc):\n    return [alpha[i][0] for i in range(len(eval(doc['choices'])))]\n",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0.0
      }
    },
    "egyptianmmlu_biology": {
      "task": "egyptianmmlu_biology",
      "task_alias": "biology",
      "tag": [
        "egyptianmmlu_stem_tasks",
        "egyptianmmlu_ar_mmlu_tasks"
      ],
      "dataset_path": "MBZUAI-Paris/EgyptianMMLU",
      "dataset_name": "biology",
      "dataset_kwargs": {
        "trust_remote_code": true
      },
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "def doc_to_text(doc):\n\n    subject = doc[\"subject_egyptian\"]\n    question = (\n        doc[\"question\"]\n        if doc[\"context\"] == \"\"\n        else f\"{doc['context']}\\n\\n{doc['question']}\"\n    )\n\n    options = []\n    for i, opt in enumerate(eval(doc[\"choices\"])):\n        options.append(f\"{alpha[i]} {opt}\")\n    doc_text = PROMPT.format(subject, question, \"\\n\".join(options))\n    return doc_text\n",
      "doc_to_target": "answer",
      "doc_to_choice": "def doc_to_choice(doc):\n    return [alpha[i][0] for i in range(len(eval(doc['choices'])))]\n",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0.0
      }
    },
    "egyptianmmlu_civics": {
      "task": "egyptianmmlu_civics",
      "task_alias": "civics",
      "tag": [
        "egyptianmmlu_social_sciences_tasks",
        "egyptianmmlu_ar_mmlu_tasks"
      ],
      "dataset_path": "MBZUAI-Paris/EgyptianMMLU",
      "dataset_name": "civics",
      "dataset_kwargs": {
        "trust_remote_code": true
      },
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "def doc_to_text(doc):\n\n    subject = doc[\"subject_egyptian\"]\n    question = (\n        doc[\"question\"]\n        if doc[\"context\"] == \"\"\n        else f\"{doc['context']}\\n\\n{doc['question']}\"\n    )\n\n    options = []\n    for i, opt in enumerate(eval(doc[\"choices\"])):\n        options.append(f\"{alpha[i]} {opt}\")\n    doc_text = PROMPT.format(subject, question, \"\\n\".join(options))\n    return doc_text\n",
      "doc_to_target": "answer",
      "doc_to_choice": "def doc_to_choice(doc):\n    return [alpha[i][0] for i in range(len(eval(doc['choices'])))]\n",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0.0
      }
    },
    "egyptianmmlu_computer_science": {
      "task": "egyptianmmlu_computer_science",
      "task_alias": "computer science",
      "tag": [
        "egyptianmmlu_stem_tasks",
        "egyptianmmlu_ar_mmlu_tasks"
      ],
      "dataset_path": "MBZUAI-Paris/EgyptianMMLU",
      "dataset_name": "computer_science",
      "dataset_kwargs": {
        "trust_remote_code": true
      },
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "def doc_to_text(doc):\n\n    subject = doc[\"subject_egyptian\"]\n    question = (\n        doc[\"question\"]\n        if doc[\"context\"] == \"\"\n        else f\"{doc['context']}\\n\\n{doc['question']}\"\n    )\n\n    options = []\n    for i, opt in enumerate(eval(doc[\"choices\"])):\n        options.append(f\"{alpha[i]} {opt}\")\n    doc_text = PROMPT.format(subject, question, \"\\n\".join(options))\n    return doc_text\n",
      "doc_to_target": "answer",
      "doc_to_choice": "def doc_to_choice(doc):\n    return [alpha[i][0] for i in range(len(eval(doc['choices'])))]\n",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0.0
      }
    },
    "egyptianmmlu_driving_test": {
      "task": "egyptianmmlu_driving_test",
      "task_alias": "driving test",
      "tag": [
        "egyptianmmlu_other_tasks",
        "egyptianmmlu_ar_mmlu_tasks"
      ],
      "dataset_path": "MBZUAI-Paris/EgyptianMMLU",
      "dataset_name": "driving_test",
      "dataset_kwargs": {
        "trust_remote_code": true
      },
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "def doc_to_text(doc):\n\n    subject = doc[\"subject_egyptian\"]\n    question = (\n        doc[\"question\"]\n        if doc[\"context\"] == \"\"\n        else f\"{doc['context']}\\n\\n{doc['question']}\"\n    )\n\n    options = []\n    for i, opt in enumerate(eval(doc[\"choices\"])):\n        options.append(f\"{alpha[i]} {opt}\")\n    doc_text = PROMPT.format(subject, question, \"\\n\".join(options))\n    return doc_text\n",
      "doc_to_target": "answer",
      "doc_to_choice": "def doc_to_choice(doc):\n    return [alpha[i][0] for i in range(len(eval(doc['choices'])))]\n",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0.0
      }
    },
    "egyptianmmlu_economics": {
      "task": "egyptianmmlu_economics",
      "task_alias": "economics",
      "tag": [
        "egyptianmmlu_social_sciences_tasks",
        "egyptianmmlu_ar_mmlu_tasks"
      ],
      "dataset_path": "MBZUAI-Paris/EgyptianMMLU",
      "dataset_name": "economics",
      "dataset_kwargs": {
        "trust_remote_code": true
      },
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "def doc_to_text(doc):\n\n    subject = doc[\"subject_egyptian\"]\n    question = (\n        doc[\"question\"]\n        if doc[\"context\"] == \"\"\n        else f\"{doc['context']}\\n\\n{doc['question']}\"\n    )\n\n    options = []\n    for i, opt in enumerate(eval(doc[\"choices\"])):\n        options.append(f\"{alpha[i]} {opt}\")\n    doc_text = PROMPT.format(subject, question, \"\\n\".join(options))\n    return doc_text\n",
      "doc_to_target": "answer",
      "doc_to_choice": "def doc_to_choice(doc):\n    return [alpha[i][0] for i in range(len(eval(doc['choices'])))]\n",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0.0
      }
    },
    "egyptianmmlu_general_knowledge": {
      "task": "egyptianmmlu_general_knowledge",
      "task_alias": "general knowledge",
      "tag": [
        "egyptianmmlu_other_tasks",
        "egyptianmmlu_ar_mmlu_tasks"
      ],
      "dataset_path": "MBZUAI-Paris/EgyptianMMLU",
      "dataset_name": "general_knowledge",
      "dataset_kwargs": {
        "trust_remote_code": true
      },
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "def doc_to_text(doc):\n\n    subject = doc[\"subject_egyptian\"]\n    question = (\n        doc[\"question\"]\n        if doc[\"context\"] == \"\"\n        else f\"{doc['context']}\\n\\n{doc['question']}\"\n    )\n\n    options = []\n    for i, opt in enumerate(eval(doc[\"choices\"])):\n        options.append(f\"{alpha[i]} {opt}\")\n    doc_text = PROMPT.format(subject, question, \"\\n\".join(options))\n    return doc_text\n",
      "doc_to_target": "answer",
      "doc_to_choice": "def doc_to_choice(doc):\n    return [alpha[i][0] for i in range(len(eval(doc['choices'])))]\n",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0.0
      }
    },
    "egyptianmmlu_geography": {
      "task": "egyptianmmlu_geography",
      "task_alias": "geography",
      "tag": [
        "egyptianmmlu_social_sciences_tasks",
        "egyptianmmlu_ar_mmlu_tasks"
      ],
      "dataset_path": "MBZUAI-Paris/EgyptianMMLU",
      "dataset_name": "geography",
      "dataset_kwargs": {
        "trust_remote_code": true
      },
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "def doc_to_text(doc):\n\n    subject = doc[\"subject_egyptian\"]\n    question = (\n        doc[\"question\"]\n        if doc[\"context\"] == \"\"\n        else f\"{doc['context']}\\n\\n{doc['question']}\"\n    )\n\n    options = []\n    for i, opt in enumerate(eval(doc[\"choices\"])):\n        options.append(f\"{alpha[i]} {opt}\")\n    doc_text = PROMPT.format(subject, question, \"\\n\".join(options))\n    return doc_text\n",
      "doc_to_target": "answer",
      "doc_to_choice": "def doc_to_choice(doc):\n    return [alpha[i][0] for i in range(len(eval(doc['choices'])))]\n",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0.0
      }
    },
    "egyptianmmlu_global_facts": {
      "task": "egyptianmmlu_global_facts",
      "task_alias": "global facts",
      "tag": [
        "egyptianmmlu_other_tasks",
        "egyptianmmlu_mmlu_tasks"
      ],
      "dataset_path": "MBZUAI-Paris/EgyptianMMLU",
      "dataset_name": "global_facts",
      "dataset_kwargs": {
        "trust_remote_code": true
      },
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "def doc_to_text(doc):\n\n    subject = doc[\"subject_egyptian\"]\n    question = (\n        doc[\"question\"]\n        if doc[\"context\"] == \"\"\n        else f\"{doc['context']}\\n\\n{doc['question']}\"\n    )\n\n    options = []\n    for i, opt in enumerate(eval(doc[\"choices\"])):\n        options.append(f\"{alpha[i]} {opt}\")\n    doc_text = PROMPT.format(subject, question, \"\\n\".join(options))\n    return doc_text\n",
      "doc_to_target": "answer",
      "doc_to_choice": "def doc_to_choice(doc):\n    return [alpha[i][0] for i in range(len(eval(doc['choices'])))]\n",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0.0
      }
    },
    "egyptianmmlu_high_school_european_history": {
      "task": "egyptianmmlu_high_school_european_history",
      "task_alias": "high school european history",
      "tag": [
        "egyptianmmlu_humanities_tasks",
        "egyptianmmlu_mmlu_tasks"
      ],
      "dataset_path": "MBZUAI-Paris/EgyptianMMLU",
      "dataset_name": "high_school_european_history",
      "dataset_kwargs": {
        "trust_remote_code": true
      },
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "def doc_to_text(doc):\n\n    subject = doc[\"subject_egyptian\"]\n    question = (\n        doc[\"question\"]\n        if doc[\"context\"] == \"\"\n        else f\"{doc['context']}\\n\\n{doc['question']}\"\n    )\n\n    options = []\n    for i, opt in enumerate(eval(doc[\"choices\"])):\n        options.append(f\"{alpha[i]} {opt}\")\n    doc_text = PROMPT.format(subject, question, \"\\n\".join(options))\n    return doc_text\n",
      "doc_to_target": "answer",
      "doc_to_choice": "def doc_to_choice(doc):\n    return [alpha[i][0] for i in range(len(eval(doc['choices'])))]\n",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0.0
      }
    },
    "egyptianmmlu_high_school_geography": {
      "task": "egyptianmmlu_high_school_geography",
      "task_alias": "high school geography",
      "tag": [
        "egyptianmmlu_social_sciences_tasks",
        "egyptianmmlu_mmlu_tasks"
      ],
      "dataset_path": "MBZUAI-Paris/EgyptianMMLU",
      "dataset_name": "high_school_geography",
      "dataset_kwargs": {
        "trust_remote_code": true
      },
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "def doc_to_text(doc):\n\n    subject = doc[\"subject_egyptian\"]\n    question = (\n        doc[\"question\"]\n        if doc[\"context\"] == \"\"\n        else f\"{doc['context']}\\n\\n{doc['question']}\"\n    )\n\n    options = []\n    for i, opt in enumerate(eval(doc[\"choices\"])):\n        options.append(f\"{alpha[i]} {opt}\")\n    doc_text = PROMPT.format(subject, question, \"\\n\".join(options))\n    return doc_text\n",
      "doc_to_target": "answer",
      "doc_to_choice": "def doc_to_choice(doc):\n    return [alpha[i][0] for i in range(len(eval(doc['choices'])))]\n",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0.0
      }
    },
    "egyptianmmlu_high_school_government_and_politics": {
      "task": "egyptianmmlu_high_school_government_and_politics",
      "task_alias": "high school government and politics",
      "tag": [
        "egyptianmmlu_social_sciences_tasks",
        "egyptianmmlu_mmlu_tasks"
      ],
      "dataset_path": "MBZUAI-Paris/EgyptianMMLU",
      "dataset_name": "high_school_government_and_politics",
      "dataset_kwargs": {
        "trust_remote_code": true
      },
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "def doc_to_text(doc):\n\n    subject = doc[\"subject_egyptian\"]\n    question = (\n        doc[\"question\"]\n        if doc[\"context\"] == \"\"\n        else f\"{doc['context']}\\n\\n{doc['question']}\"\n    )\n\n    options = []\n    for i, opt in enumerate(eval(doc[\"choices\"])):\n        options.append(f\"{alpha[i]} {opt}\")\n    doc_text = PROMPT.format(subject, question, \"\\n\".join(options))\n    return doc_text\n",
      "doc_to_target": "answer",
      "doc_to_choice": "def doc_to_choice(doc):\n    return [alpha[i][0] for i in range(len(eval(doc['choices'])))]\n",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0.0
      }
    },
    "egyptianmmlu_high_school_psychology": {
      "task": "egyptianmmlu_high_school_psychology",
      "task_alias": "high school psychology",
      "tag": [
        "egyptianmmlu_social_sciences_tasks",
        "egyptianmmlu_mmlu_tasks"
      ],
      "dataset_path": "MBZUAI-Paris/EgyptianMMLU",
      "dataset_name": "high_school_psychology",
      "dataset_kwargs": {
        "trust_remote_code": true
      },
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "def doc_to_text(doc):\n\n    subject = doc[\"subject_egyptian\"]\n    question = (\n        doc[\"question\"]\n        if doc[\"context\"] == \"\"\n        else f\"{doc['context']}\\n\\n{doc['question']}\"\n    )\n\n    options = []\n    for i, opt in enumerate(eval(doc[\"choices\"])):\n        options.append(f\"{alpha[i]} {opt}\")\n    doc_text = PROMPT.format(subject, question, \"\\n\".join(options))\n    return doc_text\n",
      "doc_to_target": "answer",
      "doc_to_choice": "def doc_to_choice(doc):\n    return [alpha[i][0] for i in range(len(eval(doc['choices'])))]\n",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0.0
      }
    },
    "egyptianmmlu_high_school_statistics": {
      "task": "egyptianmmlu_high_school_statistics",
      "task_alias": "high school statistics",
      "tag": [
        "egyptianmmlu_stem_tasks",
        "egyptianmmlu_mmlu_tasks"
      ],
      "dataset_path": "MBZUAI-Paris/EgyptianMMLU",
      "dataset_name": "high_school_statistics",
      "dataset_kwargs": {
        "trust_remote_code": true
      },
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "def doc_to_text(doc):\n\n    subject = doc[\"subject_egyptian\"]\n    question = (\n        doc[\"question\"]\n        if doc[\"context\"] == \"\"\n        else f\"{doc['context']}\\n\\n{doc['question']}\"\n    )\n\n    options = []\n    for i, opt in enumerate(eval(doc[\"choices\"])):\n        options.append(f\"{alpha[i]} {opt}\")\n    doc_text = PROMPT.format(subject, question, \"\\n\".join(options))\n    return doc_text\n",
      "doc_to_target": "answer",
      "doc_to_choice": "def doc_to_choice(doc):\n    return [alpha[i][0] for i in range(len(eval(doc['choices'])))]\n",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0.0
      }
    },
    "egyptianmmlu_high_school_world_history": {
      "task": "egyptianmmlu_high_school_world_history",
      "task_alias": "high school world history",
      "tag": [
        "egyptianmmlu_humanities_tasks",
        "egyptianmmlu_mmlu_tasks"
      ],
      "dataset_path": "MBZUAI-Paris/EgyptianMMLU",
      "dataset_name": "high_school_world_history",
      "dataset_kwargs": {
        "trust_remote_code": true
      },
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "def doc_to_text(doc):\n\n    subject = doc[\"subject_egyptian\"]\n    question = (\n        doc[\"question\"]\n        if doc[\"context\"] == \"\"\n        else f\"{doc['context']}\\n\\n{doc['question']}\"\n    )\n\n    options = []\n    for i, opt in enumerate(eval(doc[\"choices\"])):\n        options.append(f\"{alpha[i]} {opt}\")\n    doc_text = PROMPT.format(subject, question, \"\\n\".join(options))\n    return doc_text\n",
      "doc_to_target": "answer",
      "doc_to_choice": "def doc_to_choice(doc):\n    return [alpha[i][0] for i in range(len(eval(doc['choices'])))]\n",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0.0
      }
    },
    "egyptianmmlu_history": {
      "task": "egyptianmmlu_history",
      "task_alias": "history",
      "tag": [
        "egyptianmmlu_humanities_tasks",
        "egyptianmmlu_ar_mmlu_tasks"
      ],
      "dataset_path": "MBZUAI-Paris/EgyptianMMLU",
      "dataset_name": "history",
      "dataset_kwargs": {
        "trust_remote_code": true
      },
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "def doc_to_text(doc):\n\n    subject = doc[\"subject_egyptian\"]\n    question = (\n        doc[\"question\"]\n        if doc[\"context\"] == \"\"\n        else f\"{doc['context']}\\n\\n{doc['question']}\"\n    )\n\n    options = []\n    for i, opt in enumerate(eval(doc[\"choices\"])):\n        options.append(f\"{alpha[i]} {opt}\")\n    doc_text = PROMPT.format(subject, question, \"\\n\".join(options))\n    return doc_text\n",
      "doc_to_target": "answer",
      "doc_to_choice": "def doc_to_choice(doc):\n    return [alpha[i][0] for i in range(len(eval(doc['choices'])))]\n",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0.0
      }
    },
    "egyptianmmlu_human_aging": {
      "task": "egyptianmmlu_human_aging",
      "task_alias": "human aging",
      "tag": [
        "egyptianmmlu_other_tasks",
        "egyptianmmlu_mmlu_tasks"
      ],
      "dataset_path": "MBZUAI-Paris/EgyptianMMLU",
      "dataset_name": "human_aging",
      "dataset_kwargs": {
        "trust_remote_code": true
      },
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "def doc_to_text(doc):\n\n    subject = doc[\"subject_egyptian\"]\n    question = (\n        doc[\"question\"]\n        if doc[\"context\"] == \"\"\n        else f\"{doc['context']}\\n\\n{doc['question']}\"\n    )\n\n    options = []\n    for i, opt in enumerate(eval(doc[\"choices\"])):\n        options.append(f\"{alpha[i]} {opt}\")\n    doc_text = PROMPT.format(subject, question, \"\\n\".join(options))\n    return doc_text\n",
      "doc_to_target": "answer",
      "doc_to_choice": "def doc_to_choice(doc):\n    return [alpha[i][0] for i in range(len(eval(doc['choices'])))]\n",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0.0
      }
    },
    "egyptianmmlu_international_law": {
      "task": "egyptianmmlu_international_law",
      "task_alias": "international law",
      "tag": [
        "egyptianmmlu_humanities_tasks",
        "egyptianmmlu_mmlu_tasks"
      ],
      "dataset_path": "MBZUAI-Paris/EgyptianMMLU",
      "dataset_name": "international_law",
      "dataset_kwargs": {
        "trust_remote_code": true
      },
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "def doc_to_text(doc):\n\n    subject = doc[\"subject_egyptian\"]\n    question = (\n        doc[\"question\"]\n        if doc[\"context\"] == \"\"\n        else f\"{doc['context']}\\n\\n{doc['question']}\"\n    )\n\n    options = []\n    for i, opt in enumerate(eval(doc[\"choices\"])):\n        options.append(f\"{alpha[i]} {opt}\")\n    doc_text = PROMPT.format(subject, question, \"\\n\".join(options))\n    return doc_text\n",
      "doc_to_target": "answer",
      "doc_to_choice": "def doc_to_choice(doc):\n    return [alpha[i][0] for i in range(len(eval(doc['choices'])))]\n",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0.0
      }
    },
    "egyptianmmlu_islamic_studies": {
      "task": "egyptianmmlu_islamic_studies",
      "task_alias": "islamic studies",
      "tag": [
        "egyptianmmlu_humanities_tasks",
        "egyptianmmlu_ar_mmlu_tasks"
      ],
      "dataset_path": "MBZUAI-Paris/EgyptianMMLU",
      "dataset_name": "islamic_studies",
      "dataset_kwargs": {
        "trust_remote_code": true
      },
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "def doc_to_text(doc):\n\n    subject = doc[\"subject_egyptian\"]\n    question = (\n        doc[\"question\"]\n        if doc[\"context\"] == \"\"\n        else f\"{doc['context']}\\n\\n{doc['question']}\"\n    )\n\n    options = []\n    for i, opt in enumerate(eval(doc[\"choices\"])):\n        options.append(f\"{alpha[i]} {opt}\")\n    doc_text = PROMPT.format(subject, question, \"\\n\".join(options))\n    return doc_text\n",
      "doc_to_target": "answer",
      "doc_to_choice": "def doc_to_choice(doc):\n    return [alpha[i][0] for i in range(len(eval(doc['choices'])))]\n",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0.0
      }
    },
    "egyptianmmlu_jurisprudence": {
      "task": "egyptianmmlu_jurisprudence",
      "task_alias": "jurisprudence",
      "tag": [
        "egyptianmmlu_humanities_tasks",
        "egyptianmmlu_mmlu_tasks"
      ],
      "dataset_path": "MBZUAI-Paris/EgyptianMMLU",
      "dataset_name": "jurisprudence",
      "dataset_kwargs": {
        "trust_remote_code": true
      },
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "def doc_to_text(doc):\n\n    subject = doc[\"subject_egyptian\"]\n    question = (\n        doc[\"question\"]\n        if doc[\"context\"] == \"\"\n        else f\"{doc['context']}\\n\\n{doc['question']}\"\n    )\n\n    options = []\n    for i, opt in enumerate(eval(doc[\"choices\"])):\n        options.append(f\"{alpha[i]} {opt}\")\n    doc_text = PROMPT.format(subject, question, \"\\n\".join(options))\n    return doc_text\n",
      "doc_to_target": "answer",
      "doc_to_choice": "def doc_to_choice(doc):\n    return [alpha[i][0] for i in range(len(eval(doc['choices'])))]\n",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0.0
      }
    },
    "egyptianmmlu_law": {
      "task": "egyptianmmlu_law",
      "task_alias": "law",
      "tag": [
        "egyptianmmlu_humanities_tasks",
        "egyptianmmlu_ar_mmlu_tasks"
      ],
      "dataset_path": "MBZUAI-Paris/EgyptianMMLU",
      "dataset_name": "law",
      "dataset_kwargs": {
        "trust_remote_code": true
      },
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "def doc_to_text(doc):\n\n    subject = doc[\"subject_egyptian\"]\n    question = (\n        doc[\"question\"]\n        if doc[\"context\"] == \"\"\n        else f\"{doc['context']}\\n\\n{doc['question']}\"\n    )\n\n    options = []\n    for i, opt in enumerate(eval(doc[\"choices\"])):\n        options.append(f\"{alpha[i]} {opt}\")\n    doc_text = PROMPT.format(subject, question, \"\\n\".join(options))\n    return doc_text\n",
      "doc_to_target": "answer",
      "doc_to_choice": "def doc_to_choice(doc):\n    return [alpha[i][0] for i in range(len(eval(doc['choices'])))]\n",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0.0
      }
    },
    "egyptianmmlu_logical_fallacies": {
      "task": "egyptianmmlu_logical_fallacies",
      "task_alias": "logical fallacies",
      "tag": [
        "egyptianmmlu_humanities_tasks",
        "egyptianmmlu_mmlu_tasks"
      ],
      "dataset_path": "MBZUAI-Paris/EgyptianMMLU",
      "dataset_name": "logical_fallacies",
      "dataset_kwargs": {
        "trust_remote_code": true
      },
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "def doc_to_text(doc):\n\n    subject = doc[\"subject_egyptian\"]\n    question = (\n        doc[\"question\"]\n        if doc[\"context\"] == \"\"\n        else f\"{doc['context']}\\n\\n{doc['question']}\"\n    )\n\n    options = []\n    for i, opt in enumerate(eval(doc[\"choices\"])):\n        options.append(f\"{alpha[i]} {opt}\")\n    doc_text = PROMPT.format(subject, question, \"\\n\".join(options))\n    return doc_text\n",
      "doc_to_target": "answer",
      "doc_to_choice": "def doc_to_choice(doc):\n    return [alpha[i][0] for i in range(len(eval(doc['choices'])))]\n",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0.0
      }
    },
    "egyptianmmlu_management": {
      "task": "egyptianmmlu_management",
      "task_alias": "management",
      "tag": [
        "egyptianmmlu_other_tasks",
        "egyptianmmlu_mmlu_tasks"
      ],
      "dataset_path": "MBZUAI-Paris/EgyptianMMLU",
      "dataset_name": "management",
      "dataset_kwargs": {
        "trust_remote_code": true
      },
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "def doc_to_text(doc):\n\n    subject = doc[\"subject_egyptian\"]\n    question = (\n        doc[\"question\"]\n        if doc[\"context\"] == \"\"\n        else f\"{doc['context']}\\n\\n{doc['question']}\"\n    )\n\n    options = []\n    for i, opt in enumerate(eval(doc[\"choices\"])):\n        options.append(f\"{alpha[i]} {opt}\")\n    doc_text = PROMPT.format(subject, question, \"\\n\".join(options))\n    return doc_text\n",
      "doc_to_target": "answer",
      "doc_to_choice": "def doc_to_choice(doc):\n    return [alpha[i][0] for i in range(len(eval(doc['choices'])))]\n",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0.0
      }
    },
    "egyptianmmlu_management_ar": {
      "task": "egyptianmmlu_management_ar",
      "task_alias": "management ar",
      "tag": [
        "egyptianmmlu_other_tasks",
        "egyptianmmlu_ar_mmlu_tasks"
      ],
      "dataset_path": "MBZUAI-Paris/EgyptianMMLU",
      "dataset_name": "management_ar",
      "dataset_kwargs": {
        "trust_remote_code": true
      },
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "def doc_to_text(doc):\n\n    subject = doc[\"subject_egyptian\"]\n    question = (\n        doc[\"question\"]\n        if doc[\"context\"] == \"\"\n        else f\"{doc['context']}\\n\\n{doc['question']}\"\n    )\n\n    options = []\n    for i, opt in enumerate(eval(doc[\"choices\"])):\n        options.append(f\"{alpha[i]} {opt}\")\n    doc_text = PROMPT.format(subject, question, \"\\n\".join(options))\n    return doc_text\n",
      "doc_to_target": "answer",
      "doc_to_choice": "def doc_to_choice(doc):\n    return [alpha[i][0] for i in range(len(eval(doc['choices'])))]\n",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0.0
      }
    },
    "egyptianmmlu_marketing": {
      "task": "egyptianmmlu_marketing",
      "task_alias": "marketing",
      "tag": [
        "egyptianmmlu_other_tasks",
        "egyptianmmlu_mmlu_tasks"
      ],
      "dataset_path": "MBZUAI-Paris/EgyptianMMLU",
      "dataset_name": "marketing",
      "dataset_kwargs": {
        "trust_remote_code": true
      },
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "def doc_to_text(doc):\n\n    subject = doc[\"subject_egyptian\"]\n    question = (\n        doc[\"question\"]\n        if doc[\"context\"] == \"\"\n        else f\"{doc['context']}\\n\\n{doc['question']}\"\n    )\n\n    options = []\n    for i, opt in enumerate(eval(doc[\"choices\"])):\n        options.append(f\"{alpha[i]} {opt}\")\n    doc_text = PROMPT.format(subject, question, \"\\n\".join(options))\n    return doc_text\n",
      "doc_to_target": "answer",
      "doc_to_choice": "def doc_to_choice(doc):\n    return [alpha[i][0] for i in range(len(eval(doc['choices'])))]\n",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0.0
      }
    },
    "egyptianmmlu_math": {
      "task": "egyptianmmlu_math",
      "task_alias": "math",
      "tag": [
        "egyptianmmlu_stem_tasks",
        "egyptianmmlu_ar_mmlu_tasks"
      ],
      "dataset_path": "MBZUAI-Paris/EgyptianMMLU",
      "dataset_name": "math",
      "dataset_kwargs": {
        "trust_remote_code": true
      },
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "def doc_to_text(doc):\n\n    subject = doc[\"subject_egyptian\"]\n    question = (\n        doc[\"question\"]\n        if doc[\"context\"] == \"\"\n        else f\"{doc['context']}\\n\\n{doc['question']}\"\n    )\n\n    options = []\n    for i, opt in enumerate(eval(doc[\"choices\"])):\n        options.append(f\"{alpha[i]} {opt}\")\n    doc_text = PROMPT.format(subject, question, \"\\n\".join(options))\n    return doc_text\n",
      "doc_to_target": "answer",
      "doc_to_choice": "def doc_to_choice(doc):\n    return [alpha[i][0] for i in range(len(eval(doc['choices'])))]\n",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0.0
      }
    },
    "egyptianmmlu_moral_disputes": {
      "task": "egyptianmmlu_moral_disputes",
      "task_alias": "moral disputes",
      "tag": [
        "egyptianmmlu_humanities_tasks",
        "egyptianmmlu_mmlu_tasks"
      ],
      "dataset_path": "MBZUAI-Paris/EgyptianMMLU",
      "dataset_name": "moral_disputes",
      "dataset_kwargs": {
        "trust_remote_code": true
      },
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "def doc_to_text(doc):\n\n    subject = doc[\"subject_egyptian\"]\n    question = (\n        doc[\"question\"]\n        if doc[\"context\"] == \"\"\n        else f\"{doc['context']}\\n\\n{doc['question']}\"\n    )\n\n    options = []\n    for i, opt in enumerate(eval(doc[\"choices\"])):\n        options.append(f\"{alpha[i]} {opt}\")\n    doc_text = PROMPT.format(subject, question, \"\\n\".join(options))\n    return doc_text\n",
      "doc_to_target": "answer",
      "doc_to_choice": "def doc_to_choice(doc):\n    return [alpha[i][0] for i in range(len(eval(doc['choices'])))]\n",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0.0
      }
    },
    "egyptianmmlu_moral_scenarios": {
      "task": "egyptianmmlu_moral_scenarios",
      "task_alias": "moral scenarios",
      "tag": [
        "egyptianmmlu_humanities_tasks",
        "egyptianmmlu_mmlu_tasks"
      ],
      "dataset_path": "MBZUAI-Paris/EgyptianMMLU",
      "dataset_name": "moral_scenarios",
      "dataset_kwargs": {
        "trust_remote_code": true
      },
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "def doc_to_text(doc):\n\n    subject = doc[\"subject_egyptian\"]\n    question = (\n        doc[\"question\"]\n        if doc[\"context\"] == \"\"\n        else f\"{doc['context']}\\n\\n{doc['question']}\"\n    )\n\n    options = []\n    for i, opt in enumerate(eval(doc[\"choices\"])):\n        options.append(f\"{alpha[i]} {opt}\")\n    doc_text = PROMPT.format(subject, question, \"\\n\".join(options))\n    return doc_text\n",
      "doc_to_target": "answer",
      "doc_to_choice": "def doc_to_choice(doc):\n    return [alpha[i][0] for i in range(len(eval(doc['choices'])))]\n",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0.0
      }
    },
    "egyptianmmlu_natural_science": {
      "task": "egyptianmmlu_natural_science",
      "task_alias": "natural science",
      "tag": [
        "egyptianmmlu_stem_tasks",
        "egyptianmmlu_ar_mmlu_tasks"
      ],
      "dataset_path": "MBZUAI-Paris/EgyptianMMLU",
      "dataset_name": "natural_science",
      "dataset_kwargs": {
        "trust_remote_code": true
      },
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "def doc_to_text(doc):\n\n    subject = doc[\"subject_egyptian\"]\n    question = (\n        doc[\"question\"]\n        if doc[\"context\"] == \"\"\n        else f\"{doc['context']}\\n\\n{doc['question']}\"\n    )\n\n    options = []\n    for i, opt in enumerate(eval(doc[\"choices\"])):\n        options.append(f\"{alpha[i]} {opt}\")\n    doc_text = PROMPT.format(subject, question, \"\\n\".join(options))\n    return doc_text\n",
      "doc_to_target": "answer",
      "doc_to_choice": "def doc_to_choice(doc):\n    return [alpha[i][0] for i in range(len(eval(doc['choices'])))]\n",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0.0
      }
    },
    "egyptianmmlu_nutrition": {
      "task": "egyptianmmlu_nutrition",
      "task_alias": "nutrition",
      "tag": [
        "egyptianmmlu_other_tasks",
        "egyptianmmlu_mmlu_tasks"
      ],
      "dataset_path": "MBZUAI-Paris/EgyptianMMLU",
      "dataset_name": "nutrition",
      "dataset_kwargs": {
        "trust_remote_code": true
      },
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "def doc_to_text(doc):\n\n    subject = doc[\"subject_egyptian\"]\n    question = (\n        doc[\"question\"]\n        if doc[\"context\"] == \"\"\n        else f\"{doc['context']}\\n\\n{doc['question']}\"\n    )\n\n    options = []\n    for i, opt in enumerate(eval(doc[\"choices\"])):\n        options.append(f\"{alpha[i]} {opt}\")\n    doc_text = PROMPT.format(subject, question, \"\\n\".join(options))\n    return doc_text\n",
      "doc_to_target": "answer",
      "doc_to_choice": "def doc_to_choice(doc):\n    return [alpha[i][0] for i in range(len(eval(doc['choices'])))]\n",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0.0
      }
    },
    "egyptianmmlu_philosophy": {
      "task": "egyptianmmlu_philosophy",
      "task_alias": "philosophy",
      "tag": [
        "egyptianmmlu_humanities_tasks",
        "egyptianmmlu_mmlu_tasks"
      ],
      "dataset_path": "MBZUAI-Paris/EgyptianMMLU",
      "dataset_name": "philosophy",
      "dataset_kwargs": {
        "trust_remote_code": true
      },
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "def doc_to_text(doc):\n\n    subject = doc[\"subject_egyptian\"]\n    question = (\n        doc[\"question\"]\n        if doc[\"context\"] == \"\"\n        else f\"{doc['context']}\\n\\n{doc['question']}\"\n    )\n\n    options = []\n    for i, opt in enumerate(eval(doc[\"choices\"])):\n        options.append(f\"{alpha[i]} {opt}\")\n    doc_text = PROMPT.format(subject, question, \"\\n\".join(options))\n    return doc_text\n",
      "doc_to_target": "answer",
      "doc_to_choice": "def doc_to_choice(doc):\n    return [alpha[i][0] for i in range(len(eval(doc['choices'])))]\n",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0.0
      }
    },
    "egyptianmmlu_philosophy_ar": {
      "task": "egyptianmmlu_philosophy_ar",
      "task_alias": "philosophy ar",
      "tag": [
        "egyptianmmlu_humanities_tasks",
        "egyptianmmlu_ar_mmlu_tasks"
      ],
      "dataset_path": "MBZUAI-Paris/EgyptianMMLU",
      "dataset_name": "philosophy_ar",
      "dataset_kwargs": {
        "trust_remote_code": true
      },
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "def doc_to_text(doc):\n\n    subject = doc[\"subject_egyptian\"]\n    question = (\n        doc[\"question\"]\n        if doc[\"context\"] == \"\"\n        else f\"{doc['context']}\\n\\n{doc['question']}\"\n    )\n\n    options = []\n    for i, opt in enumerate(eval(doc[\"choices\"])):\n        options.append(f\"{alpha[i]} {opt}\")\n    doc_text = PROMPT.format(subject, question, \"\\n\".join(options))\n    return doc_text\n",
      "doc_to_target": "answer",
      "doc_to_choice": "def doc_to_choice(doc):\n    return [alpha[i][0] for i in range(len(eval(doc['choices'])))]\n",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0.0
      }
    },
    "egyptianmmlu_physics": {
      "task": "egyptianmmlu_physics",
      "task_alias": "physics",
      "tag": [
        "egyptianmmlu_stem_tasks",
        "egyptianmmlu_ar_mmlu_tasks"
      ],
      "dataset_path": "MBZUAI-Paris/EgyptianMMLU",
      "dataset_name": "physics",
      "dataset_kwargs": {
        "trust_remote_code": true
      },
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "def doc_to_text(doc):\n\n    subject = doc[\"subject_egyptian\"]\n    question = (\n        doc[\"question\"]\n        if doc[\"context\"] == \"\"\n        else f\"{doc['context']}\\n\\n{doc['question']}\"\n    )\n\n    options = []\n    for i, opt in enumerate(eval(doc[\"choices\"])):\n        options.append(f\"{alpha[i]} {opt}\")\n    doc_text = PROMPT.format(subject, question, \"\\n\".join(options))\n    return doc_text\n",
      "doc_to_target": "answer",
      "doc_to_choice": "def doc_to_choice(doc):\n    return [alpha[i][0] for i in range(len(eval(doc['choices'])))]\n",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0.0
      }
    },
    "egyptianmmlu_political_science": {
      "task": "egyptianmmlu_political_science",
      "task_alias": "political science",
      "tag": [
        "egyptianmmlu_social_sciences_tasks",
        "egyptianmmlu_ar_mmlu_tasks"
      ],
      "dataset_path": "MBZUAI-Paris/EgyptianMMLU",
      "dataset_name": "political_science",
      "dataset_kwargs": {
        "trust_remote_code": true
      },
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "def doc_to_text(doc):\n\n    subject = doc[\"subject_egyptian\"]\n    question = (\n        doc[\"question\"]\n        if doc[\"context\"] == \"\"\n        else f\"{doc['context']}\\n\\n{doc['question']}\"\n    )\n\n    options = []\n    for i, opt in enumerate(eval(doc[\"choices\"])):\n        options.append(f\"{alpha[i]} {opt}\")\n    doc_text = PROMPT.format(subject, question, \"\\n\".join(options))\n    return doc_text\n",
      "doc_to_target": "answer",
      "doc_to_choice": "def doc_to_choice(doc):\n    return [alpha[i][0] for i in range(len(eval(doc['choices'])))]\n",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0.0
      }
    },
    "egyptianmmlu_professional_law": {
      "task": "egyptianmmlu_professional_law",
      "task_alias": "professional law",
      "tag": [
        "egyptianmmlu_humanities_tasks",
        "egyptianmmlu_mmlu_tasks"
      ],
      "dataset_path": "MBZUAI-Paris/EgyptianMMLU",
      "dataset_name": "professional_law",
      "dataset_kwargs": {
        "trust_remote_code": true
      },
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "def doc_to_text(doc):\n\n    subject = doc[\"subject_egyptian\"]\n    question = (\n        doc[\"question\"]\n        if doc[\"context\"] == \"\"\n        else f\"{doc['context']}\\n\\n{doc['question']}\"\n    )\n\n    options = []\n    for i, opt in enumerate(eval(doc[\"choices\"])):\n        options.append(f\"{alpha[i]} {opt}\")\n    doc_text = PROMPT.format(subject, question, \"\\n\".join(options))\n    return doc_text\n",
      "doc_to_target": "answer",
      "doc_to_choice": "def doc_to_choice(doc):\n    return [alpha[i][0] for i in range(len(eval(doc['choices'])))]\n",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0.0
      }
    },
    "egyptianmmlu_professional_psychology": {
      "task": "egyptianmmlu_professional_psychology",
      "task_alias": "professional psychology",
      "tag": [
        "egyptianmmlu_social_sciences_tasks",
        "egyptianmmlu_mmlu_tasks"
      ],
      "dataset_path": "MBZUAI-Paris/EgyptianMMLU",
      "dataset_name": "professional_psychology",
      "dataset_kwargs": {
        "trust_remote_code": true
      },
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "def doc_to_text(doc):\n\n    subject = doc[\"subject_egyptian\"]\n    question = (\n        doc[\"question\"]\n        if doc[\"context\"] == \"\"\n        else f\"{doc['context']}\\n\\n{doc['question']}\"\n    )\n\n    options = []\n    for i, opt in enumerate(eval(doc[\"choices\"])):\n        options.append(f\"{alpha[i]} {opt}\")\n    doc_text = PROMPT.format(subject, question, \"\\n\".join(options))\n    return doc_text\n",
      "doc_to_target": "answer",
      "doc_to_choice": "def doc_to_choice(doc):\n    return [alpha[i][0] for i in range(len(eval(doc['choices'])))]\n",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0.0
      }
    },
    "egyptianmmlu_public_relations": {
      "task": "egyptianmmlu_public_relations",
      "task_alias": "public relations",
      "tag": [
        "egyptianmmlu_social_sciences_tasks",
        "egyptianmmlu_mmlu_tasks"
      ],
      "dataset_path": "MBZUAI-Paris/EgyptianMMLU",
      "dataset_name": "public_relations",
      "dataset_kwargs": {
        "trust_remote_code": true
      },
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "def doc_to_text(doc):\n\n    subject = doc[\"subject_egyptian\"]\n    question = (\n        doc[\"question\"]\n        if doc[\"context\"] == \"\"\n        else f\"{doc['context']}\\n\\n{doc['question']}\"\n    )\n\n    options = []\n    for i, opt in enumerate(eval(doc[\"choices\"])):\n        options.append(f\"{alpha[i]} {opt}\")\n    doc_text = PROMPT.format(subject, question, \"\\n\".join(options))\n    return doc_text\n",
      "doc_to_target": "answer",
      "doc_to_choice": "def doc_to_choice(doc):\n    return [alpha[i][0] for i in range(len(eval(doc['choices'])))]\n",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0.0
      }
    },
    "egyptianmmlu_security_studies": {
      "task": "egyptianmmlu_security_studies",
      "task_alias": "security studies",
      "tag": [
        "egyptianmmlu_social_sciences_tasks",
        "egyptianmmlu_mmlu_tasks"
      ],
      "dataset_path": "MBZUAI-Paris/EgyptianMMLU",
      "dataset_name": "security_studies",
      "dataset_kwargs": {
        "trust_remote_code": true
      },
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "def doc_to_text(doc):\n\n    subject = doc[\"subject_egyptian\"]\n    question = (\n        doc[\"question\"]\n        if doc[\"context\"] == \"\"\n        else f\"{doc['context']}\\n\\n{doc['question']}\"\n    )\n\n    options = []\n    for i, opt in enumerate(eval(doc[\"choices\"])):\n        options.append(f\"{alpha[i]} {opt}\")\n    doc_text = PROMPT.format(subject, question, \"\\n\".join(options))\n    return doc_text\n",
      "doc_to_target": "answer",
      "doc_to_choice": "def doc_to_choice(doc):\n    return [alpha[i][0] for i in range(len(eval(doc['choices'])))]\n",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0.0
      }
    },
    "egyptianmmlu_social_science": {
      "task": "egyptianmmlu_social_science",
      "task_alias": "social science",
      "tag": [
        "egyptianmmlu_social_sciences_tasks",
        "egyptianmmlu_ar_mmlu_tasks"
      ],
      "dataset_path": "MBZUAI-Paris/EgyptianMMLU",
      "dataset_name": "social_science",
      "dataset_kwargs": {
        "trust_remote_code": true
      },
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "def doc_to_text(doc):\n\n    subject = doc[\"subject_egyptian\"]\n    question = (\n        doc[\"question\"]\n        if doc[\"context\"] == \"\"\n        else f\"{doc['context']}\\n\\n{doc['question']}\"\n    )\n\n    options = []\n    for i, opt in enumerate(eval(doc[\"choices\"])):\n        options.append(f\"{alpha[i]} {opt}\")\n    doc_text = PROMPT.format(subject, question, \"\\n\".join(options))\n    return doc_text\n",
      "doc_to_target": "answer",
      "doc_to_choice": "def doc_to_choice(doc):\n    return [alpha[i][0] for i in range(len(eval(doc['choices'])))]\n",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0.0
      }
    },
    "egyptianmmlu_sociology": {
      "task": "egyptianmmlu_sociology",
      "task_alias": "sociology",
      "tag": [
        "egyptianmmlu_social_sciences_tasks",
        "egyptianmmlu_mmlu_tasks"
      ],
      "dataset_path": "MBZUAI-Paris/EgyptianMMLU",
      "dataset_name": "sociology",
      "dataset_kwargs": {
        "trust_remote_code": true
      },
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "def doc_to_text(doc):\n\n    subject = doc[\"subject_egyptian\"]\n    question = (\n        doc[\"question\"]\n        if doc[\"context\"] == \"\"\n        else f\"{doc['context']}\\n\\n{doc['question']}\"\n    )\n\n    options = []\n    for i, opt in enumerate(eval(doc[\"choices\"])):\n        options.append(f\"{alpha[i]} {opt}\")\n    doc_text = PROMPT.format(subject, question, \"\\n\".join(options))\n    return doc_text\n",
      "doc_to_target": "answer",
      "doc_to_choice": "def doc_to_choice(doc):\n    return [alpha[i][0] for i in range(len(eval(doc['choices'])))]\n",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0.0
      }
    },
    "egyptianmmlu_world_religions": {
      "task": "egyptianmmlu_world_religions",
      "task_alias": "world religions",
      "tag": [
        "egyptianmmlu_humanities_tasks",
        "egyptianmmlu_mmlu_tasks"
      ],
      "dataset_path": "MBZUAI-Paris/EgyptianMMLU",
      "dataset_name": "world_religions",
      "dataset_kwargs": {
        "trust_remote_code": true
      },
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "def doc_to_text(doc):\n\n    subject = doc[\"subject_egyptian\"]\n    question = (\n        doc[\"question\"]\n        if doc[\"context\"] == \"\"\n        else f\"{doc['context']}\\n\\n{doc['question']}\"\n    )\n\n    options = []\n    for i, opt in enumerate(eval(doc[\"choices\"])):\n        options.append(f\"{alpha[i]} {opt}\")\n    doc_text = PROMPT.format(subject, question, \"\\n\".join(options))\n    return doc_text\n",
      "doc_to_target": "answer",
      "doc_to_choice": "def doc_to_choice(doc):\n    return [alpha[i][0] for i in range(len(eval(doc['choices'])))]\n",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0.0
      }
    }
  },
  "versions": {
    "egyptianmmlu": 0,
    "egyptianmmlu_accounting": 0.0,
    "egyptianmmlu_ar_mmlu": 0,
    "egyptianmmlu_arabic_language": 0.0,
    "egyptianmmlu_arabic_language_(general)": 0.0,
    "egyptianmmlu_arabic_language_(grammar)": 0.0,
    "egyptianmmlu_biology": 0.0,
    "egyptianmmlu_civics": 0.0,
    "egyptianmmlu_computer_science": 0.0,
    "egyptianmmlu_driving_test": 0.0,
    "egyptianmmlu_economics": 0.0,
    "egyptianmmlu_general_knowledge": 0.0,
    "egyptianmmlu_geography": 0.0,
    "egyptianmmlu_global_facts": 0.0,
    "egyptianmmlu_high_school_european_history": 0.0,
    "egyptianmmlu_high_school_geography": 0.0,
    "egyptianmmlu_high_school_government_and_politics": 0.0,
    "egyptianmmlu_high_school_psychology": 0.0,
    "egyptianmmlu_high_school_statistics": 0.0,
    "egyptianmmlu_high_school_world_history": 0.0,
    "egyptianmmlu_history": 0.0,
    "egyptianmmlu_human_aging": 0.0,
    "egyptianmmlu_international_law": 0.0,
    "egyptianmmlu_islamic_studies": 0.0,
    "egyptianmmlu_jurisprudence": 0.0,
    "egyptianmmlu_law": 0.0,
    "egyptianmmlu_logical_fallacies": 0.0,
    "egyptianmmlu_management": 0.0,
    "egyptianmmlu_management_ar": 0.0,
    "egyptianmmlu_marketing": 0.0,
    "egyptianmmlu_math": 0.0,
    "egyptianmmlu_mmlu": 0,
    "egyptianmmlu_moral_disputes": 0.0,
    "egyptianmmlu_moral_scenarios": 0.0,
    "egyptianmmlu_natural_science": 0.0,
    "egyptianmmlu_nutrition": 0.0,
    "egyptianmmlu_philosophy": 0.0,
    "egyptianmmlu_philosophy_ar": 0.0,
    "egyptianmmlu_physics": 0.0,
    "egyptianmmlu_political_science": 0.0,
    "egyptianmmlu_professional_law": 0.0,
    "egyptianmmlu_professional_psychology": 0.0,
    "egyptianmmlu_public_relations": 0.0,
    "egyptianmmlu_security_studies": 0.0,
    "egyptianmmlu_social_science": 0.0,
    "egyptianmmlu_sociology": 0.0,
    "egyptianmmlu_world_religions": 0.0
  },
  "n-shot": {
    "egyptianmmlu_accounting": 0,
    "egyptianmmlu_arabic_language": 0,
    "egyptianmmlu_arabic_language_(general)": 0,
    "egyptianmmlu_arabic_language_(grammar)": 0,
    "egyptianmmlu_biology": 0,
    "egyptianmmlu_civics": 0,
    "egyptianmmlu_computer_science": 0,
    "egyptianmmlu_driving_test": 0,
    "egyptianmmlu_economics": 0,
    "egyptianmmlu_general_knowledge": 0,
    "egyptianmmlu_geography": 0,
    "egyptianmmlu_global_facts": 0,
    "egyptianmmlu_high_school_european_history": 0,
    "egyptianmmlu_high_school_geography": 0,
    "egyptianmmlu_high_school_government_and_politics": 0,
    "egyptianmmlu_high_school_psychology": 0,
    "egyptianmmlu_high_school_statistics": 0,
    "egyptianmmlu_high_school_world_history": 0,
    "egyptianmmlu_history": 0,
    "egyptianmmlu_human_aging": 0,
    "egyptianmmlu_international_law": 0,
    "egyptianmmlu_islamic_studies": 0,
    "egyptianmmlu_jurisprudence": 0,
    "egyptianmmlu_law": 0,
    "egyptianmmlu_logical_fallacies": 0,
    "egyptianmmlu_management": 0,
    "egyptianmmlu_management_ar": 0,
    "egyptianmmlu_marketing": 0,
    "egyptianmmlu_math": 0,
    "egyptianmmlu_moral_disputes": 0,
    "egyptianmmlu_moral_scenarios": 0,
    "egyptianmmlu_natural_science": 0,
    "egyptianmmlu_nutrition": 0,
    "egyptianmmlu_philosophy": 0,
    "egyptianmmlu_philosophy_ar": 0,
    "egyptianmmlu_physics": 0,
    "egyptianmmlu_political_science": 0,
    "egyptianmmlu_professional_law": 0,
    "egyptianmmlu_professional_psychology": 0,
    "egyptianmmlu_public_relations": 0,
    "egyptianmmlu_security_studies": 0,
    "egyptianmmlu_social_science": 0,
    "egyptianmmlu_sociology": 0,
    "egyptianmmlu_world_religions": 0
  },
  "higher_is_better": {
    "egyptianmmlu": {
      "acc": true
    },
    "egyptianmmlu_accounting": {
      "acc": true
    },
    "egyptianmmlu_ar_mmlu": {
      "acc": true
    },
    "egyptianmmlu_arabic_language": {
      "acc": true
    },
    "egyptianmmlu_arabic_language_(general)": {
      "acc": true
    },
    "egyptianmmlu_arabic_language_(grammar)": {
      "acc": true
    },
    "egyptianmmlu_biology": {
      "acc": true
    },
    "egyptianmmlu_civics": {
      "acc": true
    },
    "egyptianmmlu_computer_science": {
      "acc": true
    },
    "egyptianmmlu_driving_test": {
      "acc": true
    },
    "egyptianmmlu_economics": {
      "acc": true
    },
    "egyptianmmlu_general_knowledge": {
      "acc": true
    },
    "egyptianmmlu_geography": {
      "acc": true
    },
    "egyptianmmlu_global_facts": {
      "acc": true
    },
    "egyptianmmlu_high_school_european_history": {
      "acc": true
    },
    "egyptianmmlu_high_school_geography": {
      "acc": true
    },
    "egyptianmmlu_high_school_government_and_politics": {
      "acc": true
    },
    "egyptianmmlu_high_school_psychology": {
      "acc": true
    },
    "egyptianmmlu_high_school_statistics": {
      "acc": true
    },
    "egyptianmmlu_high_school_world_history": {
      "acc": true
    },
    "egyptianmmlu_history": {
      "acc": true
    },
    "egyptianmmlu_human_aging": {
      "acc": true
    },
    "egyptianmmlu_international_law": {
      "acc": true
    },
    "egyptianmmlu_islamic_studies": {
      "acc": true
    },
    "egyptianmmlu_jurisprudence": {
      "acc": true
    },
    "egyptianmmlu_law": {
      "acc": true
    },
    "egyptianmmlu_logical_fallacies": {
      "acc": true
    },
    "egyptianmmlu_management": {
      "acc": true
    },
    "egyptianmmlu_management_ar": {
      "acc": true
    },
    "egyptianmmlu_marketing": {
      "acc": true
    },
    "egyptianmmlu_math": {
      "acc": true
    },
    "egyptianmmlu_mmlu": {
      "acc": true
    },
    "egyptianmmlu_moral_disputes": {
      "acc": true
    },
    "egyptianmmlu_moral_scenarios": {
      "acc": true
    },
    "egyptianmmlu_natural_science": {
      "acc": true
    },
    "egyptianmmlu_nutrition": {
      "acc": true
    },
    "egyptianmmlu_philosophy": {
      "acc": true
    },
    "egyptianmmlu_philosophy_ar": {
      "acc": true
    },
    "egyptianmmlu_physics": {
      "acc": true
    },
    "egyptianmmlu_political_science": {
      "acc": true
    },
    "egyptianmmlu_professional_law": {
      "acc": true
    },
    "egyptianmmlu_professional_psychology": {
      "acc": true
    },
    "egyptianmmlu_public_relations": {
      "acc": true
    },
    "egyptianmmlu_security_studies": {
      "acc": true
    },
    "egyptianmmlu_social_science": {
      "acc": true
    },
    "egyptianmmlu_sociology": {
      "acc": true
    },
    "egyptianmmlu_world_religions": {
      "acc": true
    }
  },
  "n-samples": {
    "egyptianmmlu_philosophy": {
      "original": 311,
      "effective": 10
    },
    "egyptianmmlu_global_facts": {
      "original": 100,
      "effective": 10
    },
    "egyptianmmlu_sociology": {
      "original": 201,
      "effective": 10
    },
    "egyptianmmlu_security_studies": {
      "original": 245,
      "effective": 10
    },
    "egyptianmmlu_nutrition": {
      "original": 306,
      "effective": 10
    },
    "egyptianmmlu_marketing": {
      "original": 234,
      "effective": 10
    },
    "egyptianmmlu_high_school_european_history": {
      "original": 165,
      "effective": 10
    },
    "egyptianmmlu_public_relations": {
      "original": 110,
      "effective": 10
    },
    "egyptianmmlu_international_law": {
      "original": 121,
      "effective": 10
    },
    "egyptianmmlu_high_school_government_and_politics": {
      "original": 193,
      "effective": 10
    },
    "egyptianmmlu_human_aging": {
      "original": 223,
      "effective": 10
    },
    "egyptianmmlu_management": {
      "original": 103,
      "effective": 10
    },
    "egyptianmmlu_moral_scenarios": {
      "original": 895,
      "effective": 10
    },
    "egyptianmmlu_high_school_geography": {
      "original": 198,
      "effective": 10
    },
    "egyptianmmlu_professional_psychology": {
      "original": 606,
      "effective": 10
    },
    "egyptianmmlu_professional_law": {
      "original": 1534,
      "effective": 10
    },
    "egyptianmmlu_logical_fallacies": {
      "original": 163,
      "effective": 10
    },
    "egyptianmmlu_high_school_statistics": {
      "original": 216,
      "effective": 10
    },
    "egyptianmmlu_world_religions": {
      "original": 171,
      "effective": 10
    },
    "egyptianmmlu_high_school_psychology": {
      "original": 543,
      "effective": 10
    },
    "egyptianmmlu_jurisprudence": {
      "original": 108,
      "effective": 10
    },
    "egyptianmmlu_moral_disputes": {
      "original": 345,
      "effective": 10
    },
    "egyptianmmlu_high_school_world_history": {
      "original": 237,
      "effective": 10
    },
    "egyptianmmlu_history": {
      "original": 1063,
      "effective": 10
    },
    "egyptianmmlu_philosophy_ar": {
      "original": 39,
      "effective": 10
    },
    "egyptianmmlu_civics": {
      "original": 323,
      "effective": 10
    },
    "egyptianmmlu_general_knowledge": {
      "original": 1198,
      "effective": 10
    },
    "egyptianmmlu_natural_science": {
      "original": 578,
      "effective": 10
    },
    "egyptianmmlu_law": {
      "original": 314,
      "effective": 10
    },
    "egyptianmmlu_geography": {
      "original": 1367,
      "effective": 10
    },
    "egyptianmmlu_arabic_language_(grammar)": {
      "original": 365,
      "effective": 10
    },
    "egyptianmmlu_islamic_studies": {
      "original": 2209,
      "effective": 10
    },
    "egyptianmmlu_economics": {
      "original": 584,
      "effective": 10
    },
    "egyptianmmlu_accounting": {
      "original": 74,
      "effective": 10
    },
    "egyptianmmlu_computer_science": {
      "original": 541,
      "effective": 10
    },
    "egyptianmmlu_political_science": {
      "original": 210,
      "effective": 10
    },
    "egyptianmmlu_arabic_language_(general)": {
      "original": 611,
      "effective": 10
    },
    "egyptianmmlu_physics": {
      "original": 255,
      "effective": 10
    },
    "egyptianmmlu_biology": {
      "original": 1409,
      "effective": 10
    },
    "egyptianmmlu_math": {
      "original": 409,
      "effective": 10
    },
    "egyptianmmlu_management_ar": {
      "original": 75,
      "effective": 10
    },
    "egyptianmmlu_arabic_language": {
      "original": 665,
      "effective": 10
    },
    "egyptianmmlu_driving_test": {
      "original": 1211,
      "effective": 10
    },
    "egyptianmmlu_social_science": {
      "original": 945,
      "effective": 10
    }
  },
  "config": {
    "model": "hf",
    "model_args": "pretrained=google/gemma-2-2b-it,trust_remote_code=True",
    "model_num_parameters": 2614341888,
    "model_dtype": "torch.bfloat16",
    "model_revision": "main",
    "model_sha": "299a8560bedf22ed1c72a8a11e7dce4a7f9f51f8",
    "batch_size": "1",
    "batch_sizes": [],
    "device": "mps",
    "use_cache": null,
    "limit": 10.0,
    "bootstrap_iters": 100000,
    "gen_kwargs": null,
    "random_seed": 0,
    "numpy_seed": 1234,
    "torch_seed": 1234,
    "fewshot_seed": 1234
  },
  "git_hash": "53cbe0b9",
  "date": 1733069866.5638652,
  "pretty_env_info": "PyTorch version: 2.5.1\nIs debug build: False\nCUDA used to build PyTorch: None\nROCM used to build PyTorch: N/A\n\nOS: macOS 14.6 (arm64)\nGCC version: Could not collect\nClang version: 15.0.0 (clang-1500.3.9.4)\nCMake version: Could not collect\nLibc version: N/A\n\nPython version: 3.10.12 (main, Nov 22 2024, 15:03:00) [Clang 15.0.0 (clang-1500.3.9.4)] (64-bit runtime)\nPython platform: macOS-14.6-arm64-arm-64bit\nIs CUDA available: False\nCUDA runtime version: No CUDA\nCUDA_MODULE_LOADING set to: N/A\nGPU models and configuration: No CUDA\nNvidia driver version: No CUDA\ncuDNN version: No CUDA\nHIP runtime version: N/A\nMIOpen runtime version: N/A\nIs XNNPACK available: True\n\nCPU:\nApple M3 Max\n\nVersions of relevant libraries:\n[pip3] numpy==2.1.3\n[pip3] torch==2.5.1\n[conda] Could not collect",
  "transformers_version": "4.46.3",
  "upper_git_hash": null,
  "tokenizer_pad_token": [
    "<pad>",
    "0"
  ],
  "tokenizer_eos_token": [
    "<eos>",
    "1"
  ],
  "tokenizer_bos_token": [
    "<bos>",
    "2"
  ],
  "eot_token_id": 1,
  "max_length": 8192,
  "task_hashes": {},
  "model_source": "hf",
  "model_name": "google/gemma-2-2b-it",
  "model_name_sanitized": "google__gemma-2-2b-it",
  "system_instruction": null,
  "system_instruction_sha": null,
  "fewshot_as_multiturn": false,
  "chat_template": "{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'user') != (loop.index0 % 2 == 0) %}{{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') }}{% endif %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}",
  "chat_template_sha": "ecd6ae513fe103f0eb62e8ab5bfa8d0fe45c1074fa398b089c93a7e70c15cfd6",
  "start_time": 221493.271823083,
  "end_time": 221825.061744125,
  "total_evaluation_time_seconds": "331.7899210420146"
}