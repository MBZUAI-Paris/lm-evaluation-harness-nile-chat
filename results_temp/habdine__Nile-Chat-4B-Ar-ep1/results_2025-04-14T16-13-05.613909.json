{
  "results": {
    "egyptian_translation": {
      " ": " ",
      "alias": "translation"
    },
    "long_translation": {
      "alias": " - long_translation",
      "bleu,STRIP_ANSWER": 11.771754941702916,
      "bleu_stderr,STRIP_ANSWER": 6.572305809667146,
      "chrf,STRIP_ANSWER": 39.45329853251285,
      "chrf_stderr,STRIP_ANSWER": 8.228437305993015,
      "ter,STRIP_ANSWER": 80.63241106719367,
      "ter_stderr,STRIP_ANSWER": 7.1663686357894525,
      "bert,STRIP_ANSWER": 0.7150817513465881,
      "bert_stderr,STRIP_ANSWER": "N/A"
    },
    "short_translation": {
      "alias": " - short_translation",
      "bleu,STRIP_ANSWER": 29.730177875068033,
      "bleu_stderr,STRIP_ANSWER": 13.977997930347012,
      "chrf,STRIP_ANSWER": 70.18609125289376,
      "chrf_stderr,STRIP_ANSWER": 13.790426720710679,
      "ter,STRIP_ANSWER": 80.0,
      "ter_stderr,STRIP_ANSWER": 59.25215761318888,
      "bert,STRIP_ANSWER": 0.5552557557821274,
      "bert_stderr,STRIP_ANSWER": "N/A"
    }
  },
  "group_subtasks": {
    "egyptian_translation": [
      "long_translation",
      "short_translation"
    ]
  },
  "configs": {
    "long_translation": {
      "task": "long_translation",
      "dataset_path": "MBZUAI-Paris/EgyptianBench",
      "dataset_name": "single_turn_long_translation",
      "test_split": "test",
      "doc_to_text": "def doc_to_text(doc):\n    # user_input = f\"[INST] <<SYS>>\\nأنت مساعد مفيد ومحترم وصادق. أجب دائما بأكبر قدر ممكن من المساعدة بينما تكون آمنا.  يجب ألا تتضمن إجاباتك أي محتوى ضار أو غير أخلاقي أو عنصري أو جنسي أو سام أو خطير أو غير قانوني. يرجى التأكد من أن ردودك غير متحيزة اجتماعيا وإيجابية بطبيعتها.\\n\\nإذا كان السؤال لا معنى له أو لم يكن متماسكا من الناحية الواقعية، اشرح السبب بدلا من الإجابة على شيء غير صحيح. إذا كنت لا تعرف إجابة سؤال ما، فيرجى عدم مشاركة معلومات خاطئة.\\n<</SYS>>\\n\\n{0} [/INST]\"\n    # doc_text = user_input.format(doc[\"messages\"][0][\"content\"])\n    doc_text = doc[\"messages\"][0][\"content\"]\n    return doc_text\n",
      "doc_to_target": "def doc_to_target(doc):\n    return doc[\"messages\"][1][\"content\"]\n",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "bleu",
          "aggregation": "bleu",
          "higher_is_better": true
        },
        {
          "metric": "chrf",
          "aggregation": "chrf",
          "higher_is_better": true
        },
        {
          "metric": "ter",
          "aggregation": "ter",
          "higher_is_better": false
        },
        {
          "metric": "def bert(items):\n    return items\n",
          "aggregation": "def mbert(items):\n    bert_model = 'google-bert/bert-base-multilingual-cased'\n    bert_score = evaluate.load(\"bertscore\")\n    predictions, references = zip(*items)\n    bert = bert_score.compute(predictions=predictions, references=references, model_type=bert_model, num_layers=12)\n    return Average(bert['f1'])\n",
          "higher_is_better": true
        }
      ],
      "output_type": "generate_until",
      "generation_kwargs": {
        "until": [
          "<end_of_turn>",
          "<eos>",
          "</s>",
          "<|end_of_text|>",
          "<|eot_id|>",
          "<|endoftext|>"
        ],
        "do_sample": false,
        "temperature": 0.0
      },
      "repeats": 1,
      "filter_list": [
        {
          "name": "STRIP_ANSWER",
          "filter": [
            {
              "function": "strip"
            }
          ]
        }
      ],
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0
      }
    },
    "short_translation": {
      "task": "short_translation",
      "dataset_path": "MBZUAI-Paris/EgyptianBench",
      "dataset_name": "single_turn_short_translation",
      "test_split": "test",
      "doc_to_text": "def doc_to_text(doc):\n    # user_input = f\"[INST] <<SYS>>\\nأنت مساعد مفيد ومحترم وصادق. أجب دائما بأكبر قدر ممكن من المساعدة بينما تكون آمنا.  يجب ألا تتضمن إجاباتك أي محتوى ضار أو غير أخلاقي أو عنصري أو جنسي أو سام أو خطير أو غير قانوني. يرجى التأكد من أن ردودك غير متحيزة اجتماعيا وإيجابية بطبيعتها.\\n\\nإذا كان السؤال لا معنى له أو لم يكن متماسكا من الناحية الواقعية، اشرح السبب بدلا من الإجابة على شيء غير صحيح. إذا كنت لا تعرف إجابة سؤال ما، فيرجى عدم مشاركة معلومات خاطئة.\\n<</SYS>>\\n\\n{0} [/INST]\"\n    # doc_text = user_input.format(doc[\"messages\"][0][\"content\"])\n    doc_text = doc[\"messages\"][0][\"content\"]\n    return doc_text\n",
      "doc_to_target": "def doc_to_target(doc):\n    return doc[\"messages\"][1][\"content\"]\n",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "bleu",
          "aggregation": "bleu",
          "higher_is_better": true
        },
        {
          "metric": "chrf",
          "aggregation": "chrf",
          "higher_is_better": true
        },
        {
          "metric": "ter",
          "aggregation": "ter",
          "higher_is_better": false
        },
        {
          "metric": "def bert(items):\n    return items\n",
          "aggregation": "def mbert(items):\n    bert_model = 'google-bert/bert-base-multilingual-cased'\n    bert_score = evaluate.load(\"bertscore\")\n    predictions, references = zip(*items)\n    bert = bert_score.compute(predictions=predictions, references=references, model_type=bert_model, num_layers=12)\n    return Average(bert['f1'])\n",
          "higher_is_better": true
        }
      ],
      "output_type": "generate_until",
      "generation_kwargs": {
        "until": [
          "<end_of_turn>",
          "<eos>",
          "</s>",
          "<|end_of_text|>",
          "<|eot_id|>",
          "<|endoftext|>"
        ],
        "do_sample": false,
        "temperature": 0.0
      },
      "repeats": 1,
      "filter_list": [
        {
          "name": "STRIP_ANSWER",
          "filter": [
            {
              "function": "strip"
            }
          ]
        }
      ],
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0
      }
    }
  },
  "versions": {
    "long_translation": 1.0,
    "short_translation": 1.0
  },
  "n-shot": {
    "long_translation": 0,
    "short_translation": 0
  },
  "higher_is_better": {
    "egyptian_translation": {
      "bleu": true,
      "chrf": true,
      "ter": false,
      "bert": true
    },
    "long_translation": {
      "bleu": true,
      "chrf": true,
      "ter": false,
      "bert": true
    },
    "short_translation": {
      "bleu": true,
      "chrf": true,
      "ter": false,
      "bert": true
    }
  },
  "n-samples": {
    "long_translation": {
      "original": 5408,
      "effective": 2
    },
    "short_translation": {
      "original": 24094,
      "effective": 2
    }
  },
  "config": {
    "model": "hf",
    "model_args": "pretrained=habdine/Nile-Chat-4B-Ar-ep1,parallelize=True,trust_remote_code=True",
    "model_num_parameters": 3880263168,
    "model_dtype": "torch.bfloat16",
    "model_revision": "main",
    "model_sha": "",
    "batch_size": "1",
    "batch_sizes": [],
    "device": "mps",
    "use_cache": null,
    "limit": 2.0,
    "bootstrap_iters": 100000,
    "gen_kwargs": null,
    "random_seed": 0,
    "numpy_seed": 1234,
    "torch_seed": 1234,
    "fewshot_seed": 1234
  },
  "git_hash": "2b6c13e2",
  "date": 1744639657.4614139,
  "pretty_env_info": "PyTorch version: 2.5.1\nIs debug build: False\nCUDA used to build PyTorch: None\nROCM used to build PyTorch: N/A\n\nOS: macOS 14.6 (arm64)\nGCC version: Could not collect\nClang version: 15.0.0 (clang-1500.3.9.4)\nCMake version: version 3.31.6\nLibc version: N/A\n\nPython version: 3.10.12 (main, Nov 22 2024, 15:03:00) [Clang 15.0.0 (clang-1500.3.9.4)] (64-bit runtime)\nPython platform: macOS-14.6-arm64-arm-64bit\nIs CUDA available: False\nCUDA runtime version: No CUDA\nCUDA_MODULE_LOADING set to: N/A\nGPU models and configuration: No CUDA\nNvidia driver version: No CUDA\ncuDNN version: No CUDA\nHIP runtime version: N/A\nMIOpen runtime version: N/A\nIs XNNPACK available: True\n\nCPU:\nApple M3 Max\n\nVersions of relevant libraries:\n[pip3] mypy-extensions==1.0.0\n[pip3] numpy==1.26.4\n[pip3] optree==0.13.1\n[pip3] torch==2.5.1\n[pip3] torchaudio==2.5.1\n[pip3] torchmetrics==1.6.0\n[pip3] torchvision==0.20.1\n[conda] numpy                     1.26.4          py312h7f4fdc5_0  \n[conda] numpy-base                1.26.4          py312he047099_0  \n[conda] numpydoc                  1.7.0           py312hca03da5_0  \n[conda] optree                    0.14.1                   pypi_0    pypi\n[conda] torch                     2.6.0                    pypi_0    pypi",
  "transformers_version": "4.51.2",
  "upper_git_hash": null,
  "tokenizer_pad_token": [
    "<pad>",
    "0"
  ],
  "tokenizer_eos_token": [
    "<eos>",
    "1"
  ],
  "tokenizer_bos_token": [
    "<bos>",
    "2"
  ],
  "eot_token_id": 1,
  "max_length": 131072,
  "task_hashes": {
    "long_translation": "624dd3d2a092f2913e375173653152e4e6d2bcb83990a7c13c4e0ca087515f42",
    "short_translation": "172ec8c35cb4f1716a9fc2ebe78ccdf957acf460c48b8db242c1479f7af700b4"
  },
  "model_source": "hf",
  "model_name": "habdine/Nile-Chat-4B-Ar-ep1",
  "model_name_sanitized": "habdine__Nile-Chat-4B-Ar-ep1",
  "system_instruction": null,
  "system_instruction_sha": null,
  "fewshot_as_multiturn": false,
  "chat_template": "{{ bos_token }}\n{%- if messages[0]['role'] == 'system' -%}\n    {%- if messages[0]['content'] is string -%}\n        {%- set first_user_prefix = messages[0]['content'] + '\n\n' -%}\n    {%- else -%}\n        {%- set first_user_prefix = messages[0]['content'][0]['text'] + '\n\n' -%}\n    {%- endif -%}\n    {%- set loop_messages = messages[1:] -%}\n{%- else -%}\n    {%- set first_user_prefix = \"\" -%}\n    {%- set loop_messages = messages -%}\n{%- endif -%}\n{%- for message in loop_messages -%}\n    {%- if (message['role'] == 'user') != (loop.index0 % 2 == 0) -%}\n        {{ raise_exception(\"Conversation roles must alternate user/assistant/user/assistant/...\") }}\n    {%- endif -%}\n    {%- if (message['role'] == 'assistant') -%}\n        {%- set role = \"model\" -%}\n    {%- else -%}\n        {%- set role = message['role'] -%}\n    {%- endif -%}\n    {{ '<start_of_turn>' + role + '\n' + (first_user_prefix if loop.first else \"\") }}\n    {%- if message['content'] is string -%}\n        {{ message['content'] | trim }}\n    {%- elif message['content'] is iterable -%}\n        {%- for item in message['content'] -%}\n            {%- if item['type'] == 'image' -%}\n                {{ '<start_of_image>' }}\n            {%- elif item['type'] == 'text' -%}\n                {{ item['text'] | trim }}\n            {%- endif -%}\n        {%- endfor -%}\n    {%- else -%}\n        {{ raise_exception(\"Invalid content type\") }}\n    {%- endif -%}\n    {{ '<end_of_turn>\n' }}\n{%- endfor -%}\n{%- if add_generation_prompt -%}\n    {{'<start_of_turn>model\n'}}\n{%- endif -%}\n",
  "chat_template_sha": "7de1c58e208eda46e9c7f86397df37ec49883aeece39fb961e0a6b24088dd3c4",
  "start_time": 1162459.823210416,
  "end_time": 1162791.90701325,
  "total_evaluation_time_seconds": "332.0838028341532"
}